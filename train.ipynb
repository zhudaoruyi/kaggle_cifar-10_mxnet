{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T21:59:10.287442Z",
     "start_time": "2017-11-05T21:59:09.552249Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet import nd, gluon, autograd, init\n",
    "from mxnet.gluon import nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import shutil\n",
    "from mxnet.gluon.data import vision\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T21:59:10.294548Z",
     "start_time": "2017-11-05T21:59:10.289162Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run resnet.py\n",
    "%run densenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T22:01:50.495704Z",
     "start_time": "2017-11-05T22:01:50.485567Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo = False\n",
    "if demo:\n",
    "    # 注意：此处使用小训练集为便于网页编译。Kaggle的完整数据集应包括5万训练样本。\n",
    "    train_dir = 'train_tiny'\n",
    "    # 注意：此处使用小测试集为便于网页编译。Kaggle的完整数据集应包括30万测试样本。\n",
    "    test_dir = 'test_tiny'\n",
    "    # 注意：此处相应使用小批量。对Kaggle的完整数据集可设较大的整数，例如128。\n",
    "    batch_size = 1\n",
    "else:\n",
    "    train_dir = 'train'\n",
    "    test_dir = 'test'\n",
    "    batch_size = 128\n",
    "\n",
    "data_dir = '../data/kaggle_cifr-10'\n",
    "label_file = 'trainLabels.csv'\n",
    "input_dir = 'train_valid_test'\n",
    "valid_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T22:03:22.731833Z",
     "start_time": "2017-11-05T22:03:22.700799Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_train(data, label):\n",
    "    im = data.asnumpy()\n",
    "    im = np.pad(im, ((4, 4), (4, 4), (0, 0)), mode='constant', constant_values=0)\n",
    "    im = nd.array(im, dtype='float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, rand_mirror=True,\n",
    "                                    rand_crop=True,\n",
    "                                   mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                   std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1)) # channel x width x height\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "def transform_test(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                   std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return im, nd.array([label]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T22:03:25.882188Z",
     "start_time": "2017-11-05T22:03:23.498141Z"
    }
   },
   "outputs": [],
   "source": [
    "input_str = data_dir + '/' + input_dir + '/'\n",
    "\n",
    "# 读取原始图像文件。flag=1说明输入图像有三个通道（彩色）。\n",
    "train_ds = vision.ImageFolderDataset(input_str + 'train', flag=1, \n",
    "                                     transform=transform_train)\n",
    "valid_ds = vision.ImageFolderDataset(input_str + 'valid', flag=1, \n",
    "                                     transform=transform_test)\n",
    "train_valid_ds = vision.ImageFolderDataset(input_str + 'train_valid', \n",
    "                                           flag=1, transform=transform_train)\n",
    "test_ds = vision.ImageFolderDataset(input_str + 'test', flag=1, \n",
    "                                     transform=transform_test)\n",
    "\n",
    "loader = gluon.data.DataLoader\n",
    "\n",
    "train_data = loader(train_ds, 16, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds, 16, shuffle=True, last_batch='keep')\n",
    "train_valid_data = loader(train_valid_ds, 128, shuffle=True, last_batch='keep')\n",
    "test_data = loader(test_ds, 128, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T22:03:25.894109Z",
     "start_time": "2017-11-05T22:03:25.883875Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_densenet(ctx):\n",
    "    num_outputs = 10\n",
    "    net = DenseNet(growthRate=12, depth=100, reduction=0.5, bottleneck=True, nClasses=10)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net\n",
    "\n",
    "def get_resnet(ctx):\n",
    "    num_outputs = 10\n",
    "    net = ResNet164_v2(num_outputs)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T22:03:26.005898Z",
     "start_time": "2017-11-05T22:03:25.895785Z"
    }
   },
   "outputs": [],
   "source": [
    "net1 = get_densenet(mx.gpu(0))\n",
    "net1.hybridize()\n",
    "#net1.load_params('./densenet-0.9378.params', ctx=mx.gpu(0))\n",
    "#net1.load_params('./densenet-254.params', ctx=mx.gpu(0))\n",
    "#net1.load_params('./densenet-348.params', ctx=mx.gpu(0))\n",
    "net1.load_params('./densenet-0.9542.params', ctx=mx.gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T22:03:27.587888Z",
     "start_time": "2017-11-05T22:03:27.236251Z"
    }
   },
   "outputs": [],
   "source": [
    "net2 = get_resnet(mx.gpu(0))\n",
    "net2.hybridize()\n",
    "net2.load_params('./resnet-0.9544.params', ctx=mx.gpu(0))\n",
    "#net2.load_params('./resnet164v2-188.params', ctx=mx.gpu(0))\n",
    "#net2.load_params('./resnet164v2-230.params', ctx=mx.gpu(0))\n",
    "#net2.load_params('./resnet164v2-274.params', ctx=mx.gpu(0))\n",
    "#net2.load_params('./resnet164v2-364-0.954091816367-0.999844461726-5e-05-0.0005.params', ctx=mx.gpu(0))\n",
    "#net2.load_params('./resnet164v2-282.params', ctx=mx.gpu(0))\n",
    "#net2.load_params('./resnet164v2-324.params', ctx=mx.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T21:58:49.856121Z",
     "start_time": "2017-11-05T21:58:49.853728Z"
    }
   },
   "source": [
    "## Ensemble networks to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-05T22:03:29.758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combint two networks with average\n",
    "preds = []\n",
    "for data, _ in test_data:\n",
    "    output1 = nd.softmax(net1(data.as_in_context(mx.gpu(0))))\n",
    "    output2 = nd.softmax(net2(data.as_in_context(mx.gpu(0))))\n",
    "    output = nd.array((output1 + output2)/2)\n",
    "    pred_label = output.argmax(axis=1)\n",
    "    preds.extend(pred_label.astype(int).asnumpy())\n",
    "print(\"done prediction\")\n",
    "sorted_ids = list(range(1, len(test_ds) + 1))\n",
    "sorted_ids.sort(key = lambda x:str(x))\n",
    "\n",
    "df = pd.DataFrame({'id': sorted_ids, 'label': preds})\n",
    "df['label'] = df['label'].apply(lambda x: train_ds.synsets[x])\n",
    "#df.to_csv('submission-densenet-0.9378-resnet-0.9394.csv', index=False)\n",
    "#df.to_csv('submission-densenet-0.9542-resnet-0.9539-mean.csv', index=False)\n",
    "df.to_csv('submission-densenet-0.9542-resnet-0.9544-mean.csv', index=False)\n",
    "print(\"done submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T21:59:11.611615Z",
     "start_time": "2017-11-05T21:59:09.517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine two networks with max\n",
    "preds = []\n",
    "for data, _ in test_data:\n",
    "    output1 = nd.softmax(net1(data.as_in_context(mx.gpu(0))))\n",
    "    output2 = nd.softmax(net2(data.as_in_context(mx.gpu(0))))\n",
    "    output = nd.concat(*[output1, output2], dim=1)\n",
    "    pred_label = output.argmax(axis=1) % 10\n",
    "    preds.extend(pred_label.astype(int).asnumpy())\n",
    "\n",
    "sorted_ids = list(range(1, len(test_ds) + 1))\n",
    "sorted_ids.sort(key = lambda x:str(x))\n",
    "\n",
    "df = pd.DataFrame({'id': sorted_ids, 'label': preds})\n",
    "df['label'] = df['label'].apply(lambda x: train_ds.synsets[x])\n",
    "#df.to_csv('submission-densenet-0.9378-resnet-0.9394.csv', index=False)\n",
    "df.to_csv('submission-densenet-0.9542-resnet-0.9544-max.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
